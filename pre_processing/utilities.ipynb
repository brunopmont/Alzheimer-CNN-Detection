{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AJUSTA T1 PRA TAMANHO DO FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "flair_path = 'Displasia/sub-00003/anat/sub-00003_acq-T2sel_FLAIR.nii.gz'\n",
    "t1_path = 'Displasia/sub-00003/anat/sub-00003_acq-iso08_T1w.nii.gz' \n",
    "output_path = 't1_reduzido.nii.gz' # Caminho onde quer salvar\n",
    "\n",
    "# Paths das imagens\n",
    "flair_img = nib.load(flair_path)\n",
    "t1_img = nib.load(t1_path)\n",
    "\n",
    "# Data das imagens\n",
    "flair_data = flair_img.get_fdata()\n",
    "t1_data = t1_img.get_fdata()\n",
    "\n",
    "# Shape das imagens\n",
    "flair_shape = flair_data.shape\n",
    "t1_shape = t1_data.shape\n",
    "\n",
    "# Calcular o fator de escala para redimensionar a imagem T1 para o tamanho da imagem FLAIR\n",
    "scaling_factor = np.array(flair_shape) / np.array(t1_shape)\n",
    "\n",
    "# Redimensionar a imagem T1 para as dimensões da imagem FLAIR usando interpolação trilinear\n",
    "t1_rescaled = zoom(t1_data, scaling_factor, order=1)\n",
    "\n",
    "# Salvar a imagem T1 escalada\n",
    "t1_rescaled_img = nib.Nifti1Image(t1_rescaled, t1_img.affine)\n",
    "nib.save(t1_rescaled_img, output_path) # Implementar lógica para salvar a imagem redimensionada e já usá-la na próxima célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VISUALIZAÇÃO DE IMAGENS (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import load_img\n",
    "import os\n",
    "\n",
    "def get_info_data(data):\n",
    "    # Calcular percentis\n",
    "    percentil_inferior = np.percentile(data, 1)\n",
    "    percentil_superior = np.percentile(data, 99)\n",
    "    print(f\"1º percentil: {percentil_inferior}\")\n",
    "    print(f\"99º percentil: {percentil_superior}\")\n",
    "\n",
    "    # Estatísticas antes\n",
    "    print(f\"Média: {np.mean(data)}, Desvio padrão: {np.std(data)}\")\n",
    "\n",
    "    # Plotar histograma\n",
    "    plt.hist(data.flatten(), bins=500, color='blue', alpha=0.7)\n",
    "    plt.title('Histograma das Intensidades')\n",
    "    plt.xlabel('Intensidade')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.yscale('log')  # Escala log para visualizar extremos\n",
    "    plt.show()\n",
    "\n",
    "img_path = \"C:/Users/Team Taiane/Desktop/ADNI/FULL_ADNI/NIFTI_PROCESSED/test/cn/I495042.nii.gz\"\n",
    "\n",
    "# Definir as coordenadas de corte\n",
    "x_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo x\n",
    "y_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo y\n",
    "z_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo z\n",
    "\n",
    "# Carregar a imagem do cérebro e a máscara de lesão\n",
    "img_brain = load_img(img_path)\n",
    "\n",
    "# Obter os dados das imagens como arrays numpy\n",
    "brain_data = img_brain.get_fdata()\n",
    "\n",
    "print(f\"{os.path.basename(img_path)} - shape: {brain_data.shape}\")\n",
    "\n",
    "# Criar a figura para plotagem\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 10))  # Plotando 3 linhas e 6 colunas para múltiplas fatias\n",
    "\n",
    "# Plotar as fatias para o eixo x\n",
    "for i, x in enumerate(x_slices):\n",
    "    brain_sagittal = brain_data[x, :, :]  # Fatia sagital no eixo x\n",
    "    axes[0, i].imshow(brain_sagittal.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[0, i].set_title(f\"Fatia Sagital x={x}\")\n",
    "    axes[0, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Plotar as fatias para o eixo y\n",
    "for i, y in enumerate(y_slices):\n",
    "    brain_coronal = brain_data[:, y, :]  # Fatia coronal no eixo y\n",
    "    axes[1, i].imshow(brain_coronal.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[1, i].set_title(f\"Fatia Coronal y={y}\")\n",
    "    axes[1, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Plotar as fatias para o eixo z\n",
    "for i, z in enumerate(z_slices):\n",
    "    brain_axial = brain_data[:, :, z]  # Fatia axial no eixo z\n",
    "    axes[2, i].imshow(brain_axial.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[2, i].set_title(f\"Fatia Axial z={z}\")\n",
    "    axes[2, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Ajustar o layout para garantir que os títulos não se sobreponham\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PRINT SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np  # Import necessário para rotacionar as imagens\n",
    "\n",
    "path_image = \"C:/Users/Team Taiane/Desktop/ADNI/FULL_ADNI/raw_data/3D_BRAIN_NOT_NORMALIZED/train/emci/I192258.nii.gz\"\n",
    "image_7 = nib.load(path_image).get_fdata()\n",
    "\n",
    "for i in range(image_7.shape[2]):\n",
    "    #plt.subplot(1, 7, i + 1)\n",
    "    rotated_slice = np.rot90(image_7[:, :, i], k=1)  # Rotação de 90 graus no sentido anti-horário\n",
    "    plt.imshow(rotated_slice, cmap='gray')  # Use cmap='gray' para escala de cinza\n",
    "    plt.title(f'Slice {i + 1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DOWNSAMPLING (DICOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from math import ceil, floor\n",
    "\n",
    "def explore_folder(directory, string): # função para percorrer cada diretório e retornar todos os caminhos de .nii.gz\n",
    "    paths =  []\n",
    "    for item in os.listdir(directory):\n",
    "        folder = os.path.join(directory, item, 'ADNI')\n",
    "        for subject in os.listdir(folder):\n",
    "            patient = os.path.join(folder, subject, string)\n",
    "            for date in os.listdir(patient):\n",
    "                exam = os.path.join(patient, date)\n",
    "                for file in os.listdir(exam):\n",
    "                    file_path = os.path.join(exam, file)\n",
    "                    paths.append(file_path)\n",
    "    return paths\n",
    "\n",
    "base = 'MPRAGE'\n",
    "classification = 'ad' \n",
    "directory = os.path.join(base, classification)\n",
    "\n",
    "# pra guardar os endereços dos arquivos da classe\n",
    "paths = []\n",
    "\n",
    "# testar se há subpastas vazias\n",
    "empty_subjects = 0 \n",
    "empty_exams = 0\n",
    "\n",
    "# enche o vetor\n",
    "paths = explore_folder(directory, 'MPRAGE')\n",
    "\n",
    "# print(paths)\n",
    "\n",
    "print(f\"Total de arquivos: {len(paths)}\")\n",
    "print(f\"Total de exames vazias: {empty_exams}\")\n",
    "print(f\"Total de pacientes vazias: {empty_subjects}\")\n",
    "\n",
    "total_paths = len(paths)\n",
    "\n",
    "target_count = 735 # valor para o qual deseja-se reduzir o número de amostras\n",
    "\n",
    "random.shuffle(paths) # embaralha vetor para fazer remoção sem viés\n",
    "\n",
    "# remover até que a lista tenha target_count itens\n",
    "while total_paths > target_count:\n",
    "    path_to_remove = paths.pop()\n",
    "\n",
    "    #shutil.rmtree(path_to_remove)  # Remove o diretório (com seus conteúdos)\n",
    "    print(f\"Pasta removida: {path_to_remove}\")\n",
    "    \n",
    "    total_paths -= 1  # decrementa a quantidade de arquivos/pastas removidos\n",
    "\n",
    "# agora, a lista de paths deve ter target_count itens restantes\n",
    "print(f\"Restando {len(paths)} arquivos/pastas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DIVISÃO ENTRE CONJUNTOS (DICOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'ad' # classe a ser dividida\n",
    "cont = 0\n",
    "\n",
    "# caminhos de cada conjunto\n",
    "train_folder = os.path.join('conjuntos', 'train', group)\n",
    "val_folder = os.path.join('conjuntos', 'validation', group)\n",
    "test_folder = os.path.join('conjuntos', 'test', group)\n",
    "\n",
    "# diretórios usados com os arquivos espalhados\n",
    "mp_dir = os.path.join('MPRAGE', group)\n",
    "sense_dir = os.path.join('SENSE2', group)\n",
    "\n",
    "# vetores para armazenar os caminhos já divididos entre os conjuntos\n",
    "train_paths = []\n",
    "val_paths = []\n",
    "test_paths = []\n",
    "\n",
    "# retornar os caminhos para cada arquivo .nii.gz espalhado\n",
    "mp_paths = explore_folder(mp_dir, 'MPRAGE')\n",
    "sense_paths = explore_folder(sense_dir, 'MPRAGE_SENSE2')\n",
    "full_paths = mp_paths + sense_paths\n",
    "\n",
    "# calcular quantos arquivos vão pra cada conjunto\n",
    "n = len(full_paths)\n",
    "train = floor(n*0.7)\n",
    "validation = floor(n*0.2)\n",
    "test = floor(n*0.1)\n",
    "\n",
    "print(f\"full: {n}\\ntrain (70): {train}\\nvalidation (20): {validation}\\ntest (10): {test}\\nsoma: {train+validation+test}\\n\\n\")\n",
    "\n",
    "# enche cada vetor\n",
    "for path in full_paths:\n",
    "    if cont < train:\n",
    "        cont += 1\n",
    "        train_paths.append(path)\n",
    "    elif cont < train+validation:\n",
    "        cont += 1\n",
    "        val_paths.append(path)\n",
    "    else:\n",
    "        test_paths.append(path)\n",
    "\n",
    "print(f\"train (70): {len(train_paths)}\\nvalidation (20): {len(val_paths)}\\ntest (10): {len(test_paths)}\\nsoma: {len(train_paths)+len(val_paths)+len(test_paths)}\\n\\n\")\n",
    "\n",
    "# copia o item do endereço antigo para um novo\n",
    "for item in train_paths:\n",
    "    shutil.copytree(item, os.path.join(train_folder, os.path.basename(item)))\n",
    "for item in val_paths:\n",
    "    shutil.copytree(item, os.path.join(val_folder, os.path.basename(item)))\n",
    "for item in test_paths:\n",
    "    shutil.copytree(item, os.path.join(test_folder, os.path.basename(item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CROPPAR IMAGENS (NIFTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# índices de corte para o corte NIfTI\n",
    "SLICE_NII_IDX0 = slice(24, 169)\n",
    "SLICE_NII_IDX1 = slice(24, 206)\n",
    "SLICE_NII_IDX2 = slice(6, 161)\n",
    "\n",
    "base = 'train'\n",
    "dir = 'ad'\n",
    "\n",
    "for subset in os.listdir(base):\n",
    "    dir = os.path.join(base, subset) # salva junção do conjunto com a pasta referente à classe\n",
    "    for name in os.listdir(dir):\n",
    "        file = os.path.join(dir, name) # acessa cada arquivo dentro da pasta\n",
    "        image = nib.load(file)\n",
    "        data = image.get_fdata()\n",
    "\n",
    "        print(f\"shape da imagem {name} original: {data.shape}\")\n",
    "        data_cropped = data[SLICE_NII_IDX0, SLICE_NII_IDX1, SLICE_NII_IDX2] # corta a imagem para o tamanho desejadao\n",
    "        print(f\"shape da imagem {name} cortada: {data_cropped.shape}\\n\\n\")\n",
    "\n",
    "        # criar um novo objeto NIfTI com o corte\n",
    "        nifti_cropped = nib.Nifti1Image(data_cropped, image.affine, image.header)\n",
    "        \n",
    "        # salvar no mesmo arquivo (sobrescrevendo)\n",
    "        nib.save(nifti_cropped, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PEGAR SLICES DO VOLUME 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ants\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def winsorize_image(image_data, lower_percentile=1, upper_percentile=99): #reduz valores extremos\n",
    "    lower_bound = np.percentile(image_data, lower_percentile)\n",
    "    upper_bound = np.percentile(image_data, upper_percentile)\n",
    "    winsorized_data = np.clip(image_data, lower_bound, upper_bound)\n",
    "    return winsorized_data\n",
    "\n",
    "# Normalization -> valores de voxels entre 0 e 1\n",
    "def normalize_image_min(image_data): \n",
    "    min_val = np.min(image_data)\n",
    "    max_val = np.max(image_data)\n",
    "    normalized_data = (image_data - min_val) / (max_val - min_val)\n",
    "    return normalized_data\n",
    "\n",
    "def reshape_img(input_folder, output_folder, item, slice_idx, axis):\n",
    "    input_path = os.path.join(input_folder, item)\n",
    "    #print(f\"IMAGEM {input_path} SENDO REDIMENSIONADA.\")\n",
    "    output_path = os.path.join(output_folder, item)\n",
    "\n",
    "    img_3d = ants.image_read(input_path)\n",
    "    data_2d = img_3d.numpy()\n",
    "\n",
    "    if axis == 0: #sagital -> x\n",
    "        data_2d = data_2d[slice_idx, :, :]\n",
    "    elif axis == 1: # coronal -> y\n",
    "        data_2d = data_2d[:, slice_idx, :]\n",
    "    elif axis == 2: # sagital -> z\n",
    "        data_2d = data_2d[:, :, slice_idx]\n",
    "        \n",
    "    data_2d = normalize_image_min(data_2d)\n",
    "    img_2d = ants.from_numpy(data_2d)\n",
    "    \n",
    "    ants.image_write(img_2d, output_path)\n",
    "    print(f\"IMAGEM SALVA EM {output_path}\\n\")\n",
    "\n",
    "\n",
    "DIR_BASE = \"/mnt/c/Users/Team Taiane/Desktop/ADNI/FULL_ADNI/raw_data/3D_BRAIN_NOT_NORMALIZED\"\n",
    "DIR_2D = \"/mnt/c/Users/Team Taiane/Desktop/ADNI/FULL_ADNI/processed_5_slices_data/axial\"\n",
    "\n",
    "x_idx = 80 # sagital\n",
    "y_idx = 73 # coronal\n",
    "z_idx = 88 # axial\n",
    "\n",
    "axis = 2 # eixo das fatias que pegaremos (0 para sagital, 1 para coronal e 2 para sagital)\n",
    "\n",
    "slice_idx = (80, 84, 88, 92, 96) # slices a serem salvos\n",
    "\n",
    "for subfolder in ['test', 'train', 'validation']:\n",
    "    print(f\"\\n\\nDIRECTORY: {subfolder}\\n\\n\")\n",
    "    input_dir = os.path.join(DIR_BASE, subfolder)\n",
    "    output_dir = os.path.join(DIR_2D, subfolder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for group in os.listdir(input_dir):\n",
    "        print(f\"GROUP: {group}\\n\\n\")\n",
    "        input_folder = os.path.join(input_dir, group)            \n",
    "        output_folder = os.path.join(output_dir, group)       \n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        already_processed = [file for file in os.listdir(output_folder)] # checa se alguma já foi processada\n",
    "        image_paths = [file for file in os.listdir(input_folder) if file not in already_processed] # carrega as imagens não processadas\n",
    "\n",
    "        #for item in image_paths:\n",
    "        #     reshape_img(input_folder, output_folder, item, slice_idx)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "            futures = [executor.submit(reshape_img, input_folder, output_folder, item, slice_idx, axis) for item in image_paths]\n",
    "\n",
    "            # Aguarda todas as tarefas terminarem\n",
    "            for future in futures:\n",
    "                future.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
