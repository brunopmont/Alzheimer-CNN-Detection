{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AJUSTA T1 PRA TAMANHO DO FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "flair_path = 'Displasia/sub-00003/anat/sub-00003_acq-T2sel_FLAIR.nii.gz'\n",
    "t1_path = 'Displasia/sub-00003/anat/sub-00003_acq-iso08_T1w.nii.gz' \n",
    "output_path = 't1_reduzido.nii.gz' # Caminho onde quer salvar\n",
    "\n",
    "# Paths das imagens\n",
    "flair_img = nib.load(flair_path)\n",
    "t1_img = nib.load(t1_path)\n",
    "\n",
    "# Data das imagens\n",
    "flair_data = flair_img.get_fdata()\n",
    "t1_data = t1_img.get_fdata()\n",
    "\n",
    "# Shape das imagens\n",
    "flair_shape = flair_data.shape\n",
    "t1_shape = t1_data.shape\n",
    "\n",
    "# Calcular o fator de escala para redimensionar a imagem T1 para o tamanho da imagem FLAIR\n",
    "scaling_factor = np.array(flair_shape) / np.array(t1_shape)\n",
    "\n",
    "# Redimensionar a imagem T1 para as dimensões da imagem FLAIR usando interpolação trilinear\n",
    "t1_rescaled = zoom(t1_data, scaling_factor, order=1)  # order=1 para interpolação bilinear\n",
    "\n",
    "# Salvar a imagem T1 escalada\n",
    "t1_rescaled_img = nib.Nifti1Image(t1_rescaled, t1_img.affine)\n",
    "nib.save(t1_rescaled_img, output_path) # Implementar lógica para salvar a imagem redimensionada e já usá-la na próxima célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VISUALIZAÇÃO DE IMAGENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import load_img\n",
    "import os\n",
    "\n",
    "img_path = \"C:/Users/Team Taiane/Desktop/ADNI/FULL_ADNI/NIFTI_PROCESSED/test/cn/I495042.nii.gz\"\n",
    "\n",
    "# Definir as coordenadas de corte\n",
    "x_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo x\n",
    "y_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo y\n",
    "z_slices = [60, 90, 120]  # Coordenadas para as fatias no eixo z\n",
    "\n",
    "# Carregar a imagem do cérebro e a máscara de lesão\n",
    "img_brain = load_img(img_path)\n",
    "\n",
    "# Obter os dados das imagens como arrays numpy\n",
    "brain_data = img_brain.get_fdata()\n",
    "\n",
    "print(f\"{os.path.basename(img_path)} - shape: {brain_data.shape}\")\n",
    "\n",
    "# Criar a figura para plotagem\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 10))  # Plotando 3 linhas e 6 colunas para múltiplas fatias\n",
    "\n",
    "# Plotar as fatias para o eixo x\n",
    "for i, x in enumerate(x_slices):\n",
    "    brain_sagittal = brain_data[x, :, :]  # Fatia sagital no eixo x\n",
    "    axes[0, i].imshow(brain_sagittal.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[0, i].set_title(f\"Fatia Sagital x={x}\")\n",
    "    axes[0, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Plotar as fatias para o eixo y\n",
    "for i, y in enumerate(y_slices):\n",
    "    brain_coronal = brain_data[:, y, :]  # Fatia coronal no eixo y\n",
    "    axes[1, i].imshow(brain_coronal.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[1, i].set_title(f\"Fatia Coronal y={y}\")\n",
    "    axes[1, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Plotar as fatias para o eixo z\n",
    "for i, z in enumerate(z_slices):\n",
    "    brain_axial = brain_data[:, :, z]  # Fatia axial no eixo z\n",
    "    axes[2, i].imshow(brain_axial.T, cmap=\"gray\", origin=\"lower\")  # Exibe a fatia do cérebro\n",
    "    axes[2, i].set_title(f\"Fatia Axial z={z}\")\n",
    "    axes[2, i].axis(\"off\")  # Desativar os eixos\n",
    "\n",
    "# Ajustar o layout para garantir que os títulos não se sobreponham\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DOWNSAMPLING (DICOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from math import ceil, floor\n",
    "\n",
    "def explore_folder(directory, string): # função para percorrer cada diretório e retornar todos os caminhos de .nii.gz\n",
    "    paths =  []\n",
    "    for item in os.listdir(directory):\n",
    "        folder = os.path.join(directory, item, 'ADNI')\n",
    "        for subject in os.listdir(folder):\n",
    "            patient = os.path.join(folder, subject, string)\n",
    "            for date in os.listdir(patient):\n",
    "                exam = os.path.join(patient, date)\n",
    "                for file in os.listdir(exam):\n",
    "                    file_path = os.path.join(exam, file)\n",
    "                    paths.append(file_path)\n",
    "    return paths\n",
    "\n",
    "base = 'MPRAGE'\n",
    "classification = 'ad' \n",
    "directory = os.path.join(base, classification)\n",
    "\n",
    "# pra guardar os endereços dos arquivos da classe\n",
    "paths = []\n",
    "\n",
    "# testar se há subpastas vazias\n",
    "empty_subjects = 0 \n",
    "empty_exams = 0\n",
    "\n",
    "# enche o vetor\n",
    "paths = explore_folder(directory, 'MPRAGE')\n",
    "\n",
    "#print(paths)\n",
    "\n",
    "print(f\"Total de arquivos: {len(paths)}\")\n",
    "print(f\"Total de exames vazias: {empty_exams}\")\n",
    "print(f\"Total de pacientes vazias: {empty_subjects}\")\n",
    "\n",
    "total_paths = len(paths)\n",
    "\n",
    "target_count = 735 # valor para o qual deseja-se reduzir o número de amostras\n",
    "\n",
    "random.shuffle(paths) # embaralha vetor para fazer remoção sem viés\n",
    "\n",
    "# remover até que a lista tenha target_count itens\n",
    "while total_paths > target_count:\n",
    "    path_to_remove = paths.pop()\n",
    "\n",
    "    #shutil.rmtree(path_to_remove)  # Remove o diretório (com seus conteúdos)\n",
    "    print(f\"Pasta removida: {path_to_remove}\")\n",
    "    \n",
    "    total_paths -= 1  # decrementa a quantidade de arquivos/pastas removidos\n",
    "\n",
    "# agora, a lista de paths deve ter target_count itens restantes\n",
    "print(f\"Restando {len(paths)} arquivos/pastas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DIVISÃO ENTRE CONJUNTOS (DICOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'ad' # classe a ser dividida\n",
    "cont = 0\n",
    "\n",
    "# caminhos de cada conjunto\n",
    "train_folder = os.path.join('conjuntos', 'train', group)\n",
    "val_folder = os.path.join('conjuntos', 'validation', group)\n",
    "test_folder = os.path.join('conjuntos', 'test', group)\n",
    "\n",
    "# diretórios usados com os arquivos espalhados\n",
    "mp_dir = os.path.join('MPRAGE', group)\n",
    "sense_dir = os.path.join('SENSE2', group)\n",
    "\n",
    "# vetores para armazenar os caminhos já divididos entre os conjuntos\n",
    "train_paths = []\n",
    "val_paths = []\n",
    "test_paths = []\n",
    "\n",
    "# retornar os caminhos para cada arquivo .nii.gz espalhado\n",
    "mp_paths = explore_folder(mp_dir, 'MPRAGE')\n",
    "sense_paths = explore_folder(sense_dir, 'MPRAGE_SENSE2')\n",
    "full_paths = mp_paths + sense_paths\n",
    "\n",
    "# calcular quantos arquivos vão pra cada conjunto\n",
    "n = len(full_paths)\n",
    "train = floor(n*0.7)\n",
    "validation = floor(n*0.2)\n",
    "test = floor(n*0.1)\n",
    "\n",
    "print(f\"full: {n}\\ntrain (70): {train}\\nvalidation (20): {validation}\\ntest (10): {test}\\nsoma: {train+validation+test}\\n\\n\")\n",
    "\n",
    "# enche cada vetor\n",
    "for path in full_paths:\n",
    "    if cont < train:\n",
    "        cont += 1\n",
    "        train_paths.append(path)\n",
    "    elif cont < train+validation:\n",
    "        cont += 1\n",
    "        val_paths.append(path)\n",
    "    else:\n",
    "        test_paths.append(path)\n",
    "\n",
    "print(f\"train (70): {len(train_paths)}\\nvalidation (20): {len(val_paths)}\\ntest (10): {len(test_paths)}\\nsoma: {len(train_paths)+len(val_paths)+len(test_paths)}\\n\\n\")\n",
    "\n",
    "# copia o item do endereço antigo para um novo\n",
    "for item in train_paths:\n",
    "    shutil.copytree(item, os.path.join(train_folder, os.path.basename(item)))\n",
    "for item in val_paths:\n",
    "    shutil.copytree(item, os.path.join(val_folder, os.path.basename(item)))\n",
    "for item in test_paths:\n",
    "    shutil.copytree(item, os.path.join(test_folder, os.path.basename(item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CROPPAR IMAGENS (NIFTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# índices de corte para o corte NIfTI\n",
    "SLICE_NII_IDX0 = slice(24, 169)\n",
    "SLICE_NII_IDX1 = slice(24, 206)\n",
    "SLICE_NII_IDX2 = slice(6, 161)\n",
    "\n",
    "base = 'train'\n",
    "dir = 'ad'\n",
    "\n",
    "for subset in os.listdir(base):\n",
    "    dir = os.path.join(base, subset) # salva junção do conjunto com a pasta referente à classe\n",
    "    for name in os.listdir(dir):\n",
    "        file = os.path.join(dir, name) # acessa cada arquivo dentro da pasta\n",
    "        image = nib.load(file)\n",
    "        data = image.get_fdata()\n",
    "\n",
    "        print(f\"shape da imagem {name} original: {data.shape}\")\n",
    "        data_cropped = data[SLICE_NII_IDX0, SLICE_NII_IDX1, SLICE_NII_IDX2] # corta a imagem para o tamanho desejadao\n",
    "        print(f\"shape da imagem {name} cortada: {data_cropped.shape}\\n\\n\")\n",
    "\n",
    "        # criar um novo objeto NIfTI com o corte\n",
    "        nifti_cropped = nib.Nifti1Image(data_cropped, image.affine, image.header)\n",
    "        \n",
    "        # salvar no mesmo arquivo (sobrescrevendo)\n",
    "        nib.save(nifti_cropped, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
